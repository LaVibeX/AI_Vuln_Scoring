{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Research Internship:** Vulnerability Scoring using AI\n",
    "###  *by Andres Tito*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tokens are present and non-empty.\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "\n",
    "tokens = ['GPT_TOKEN', 'FREE_TOKEN', 'GITHUB_TOKEN_LLM']\n",
    "\n",
    "# Dictionary to store the results\n",
    "missing_tokens = []\n",
    "\n",
    "# Iterate through the tokens and check if they exist and are not empty\n",
    "for token in tokens:\n",
    "    value = os.getenv(token)\n",
    "    if not value:\n",
    "        missing_tokens.append(token)\n",
    "\n",
    "# Report the results\n",
    "if missing_tokens:\n",
    "    raise Exception(f\"The following tokens are missing or empty: {', '.join(missing_tokens)}\")\n",
    "else:\n",
    "    print(\"All tokens are present and non-empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous  Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.get_all_GHSA import main as get_ghsa\n",
    "from scripts.get_all_NVD import main as get_nvd\n",
    "from scripts.get_RedHat import main as get_redhat\n",
    "\n",
    "def check_and_run(json_file, main_function):\n",
    "    if not os.path.exists(json_file):\n",
    "        print(f\"{json_file} not found. Running {main_function.__name__}...\")\n",
    "        try:\n",
    "            main_function()\n",
    "            print(f\"Successfully ran {main_function.__name__}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error running {main_function.__name__}: {e}\")\n",
    "    else:\n",
    "        print(f\"{json_file} exists. Skipping retrieving of data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_descriptions(df, column_name):\n",
    "    # Replace both \\n and \\r with a space in the specified column\n",
    "    df[column_name] = df[column_name].str.replace(r'[\\n\\r]', ' ', regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_existing_csv(csv_file):\n",
    "    \"\"\"Load DataFrame from CSV if it exists and is not empty.\"\"\"\n",
    "    if os.path.exists(csv_file) and os.path.getsize(csv_file) > 0:\n",
    "        try:\n",
    "            results_df = pd.read_csv(csv_file)\n",
    "            if not results_df.empty:\n",
    "                return results_df\n",
    "            else:\n",
    "                print(\"CSV file is empty.\")\n",
    "                return pd.DataFrame()\n",
    "        except pd.errors.EmptyDataError:\n",
    "            print(\"CSV file exists but is empty.\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(\"CSV file not found or is empty.\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_cvss_vector(df, column_name):\n",
    "    def clean_and_correct_scope(cvss_vector):\n",
    "        if not isinstance(cvss_vector, str):\n",
    "            return cvss_vector  # Return as is if not a string (e.g., NaN or None)\n",
    "\n",
    "        # Step 1: Replace 'SC:' with 'S:' (Scope: Changed)\n",
    "        cleaned_vector = re.sub(r'/SC:', '/S:', cvss_vector, flags=re.IGNORECASE)\n",
    "\n",
    "        # Step 2: Remove multiple occurrences of '/S:' and insert '/S:U' (Scope: Unchanged)\n",
    "        scope_matches = re.findall(r'/S:[CU]', cleaned_vector)\n",
    "        \n",
    "        # If two or more /S: exist, replace them with just /S:U\n",
    "        if len(scope_matches) > 1:\n",
    "            cleaned_vector = re.sub(r'/S:[CU]', '', cleaned_vector)  # Remove all existing /S:[C or U]\n",
    "            cleaned_vector = re.sub(r'(/C:)', '/S:U\\\\1', cleaned_vector)  # Insert '/S:U' before the first '/C:'\n",
    "\n",
    "        # Step 3: Remove any extra spaces from the vector\n",
    "        cleaned_vector = re.sub(r'\\s+', '', cleaned_vector)\n",
    "\n",
    "        return cleaned_vector\n",
    "\n",
    "    # Apply the cleaning function to the specified column\n",
    "    df[column_name] = df[column_name].apply(clean_and_correct_scope)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 1: Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.1 Retrieving Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cve_data/GHSA_cves.json exists. Skipping retrieving of data.\n",
      "./cve_data/NVD_cves.json exists. Skipping retrieving of data.\n",
      "./cve_data/RedHat_cves.json exists. Skipping retrieving of data.\n"
     ]
    }
   ],
   "source": [
    "# Check for each JSON file and call the corresponding main function if necessary\n",
    "check_and_run('./cve_data/GHSA_cves.json', get_ghsa)\n",
    "check_and_run('./cve_data/NVD_cves.json', get_nvd)\n",
    "check_and_run('./cve_data/RedHat_cves.json', get_redhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2 Cleaning Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.1 Red Hat Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "RedHat_cve = pd.read_json('./cve_data/RedHat_cves.json')\n",
    "RedHat_cve = RedHat_cve.rename(columns={ 'bugzilla_description' : 'Description',\n",
    "                                        'cvss3_score': 'Score',\n",
    "                                        'cvss3_scoring_vector': 'Vector',\n",
    "                                        'resource_url': 'url'\n",
    "                                          })\n",
    "RedHat_cve = clean_descriptions(RedHat_cve, 'Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropna: 34440\n",
      "Number of rows after dropna: 16262\n"
     ]
    }
   ],
   "source": [
    "RedHat_cve = RedHat_cve[['CVE', 'CWE', 'severity', 'Description', 'Score', 'Vector','url']]\n",
    "#Rows without CWE, CVE or Description are not useful\n",
    "print(f\"Number of rows before dropna: {RedHat_cve.shape[0]}\")\n",
    "cleanData_RedHat = RedHat_cve.dropna(subset=['CWE', 'CVE', 'Description','Score'])\n",
    "print(f\"Number of rows after dropna: {cleanData_RedHat.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData_RedHat.to_csv(\"./datasets/RedHat_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.2 NVD CVES Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NVD_cves = pd.read_json('./cve_data/NVD_cves.json')\n",
    "NVD_cves = NVD_cves.rename(columns={  'id' : 'CVE',\n",
    "                                          'description': 'Description', \n",
    "                                          'weakness_description':'CWE',\n",
    "                                          'primary_baseScore':'Score',\n",
    "                                          'primary_vectorString':'Vector',\n",
    "                                          'primary_source':'source',\n",
    "                                          'secondary_baseScore':'Score2',\n",
    "                                          'secondary_vectorString':'Vector2',\n",
    "                                          'secondary_source':'source2',\n",
    "                                          'patch_url' : 'url'\n",
    "                                          })\n",
    "NVD_cves = NVD_cves.drop(['sourceIdentifier'],axis=1)\n",
    "NVD_cves = clean_descriptions(NVD_cves, 'Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scoreIsNull_NVD = NVD_cves[NVD_cves['Score'].isnull()]\n",
    "cleanData_NVD = NVD_cves.dropna(subset=['CWE', 'CVE', 'Description'])\n",
    "cleanData_NVD = cleanData_NVD.query('CWE != \"NVD-CWE-Other\" and CWE != \"NVD-CWE-noinfo\"')\n",
    "\n",
    "#Get Dataframe of CVEs with either primary score or secondary score, if both are NaN drop.\n",
    "cleanData_NVD_full = cleanData_NVD.dropna(subset=['Score', 'Score2'], how='all')\n",
    "\n",
    "#Separate Primary and Secondary Score in different tables\n",
    "cleanData_NVD1 = cleanData_NVD.dropna(subset=['Score'])\n",
    "cleanData_NVD1 = cleanData_NVD1.drop(['Score2', 'Vector2','source2'],axis=1)\n",
    "\n",
    "\n",
    "cleanData_NVD2 = cleanData_NVD.dropna(subset=['Score2'])\n",
    "cleanData_NVD2 = cleanData_NVD2.drop(['Score', 'Vector','source'],axis=1)\n",
    "cleanData_NVD2 = cleanData_NVD2.rename(columns={  'Score2' : 'Score',\n",
    "                                          'Vector2': 'Vector', \n",
    "                                          'source2':'source',\n",
    "                                          })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData_NVD1.to_csv(\"./datasets/NVD1_df.csv\", index=False)\n",
    "cleanData_NVD2.to_csv(\"./datasets/NVD2_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_270532/2454451700.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cleanData_NVD_full_new['CVE_Year'] = cleanData_NVD_full_new['CVE'].str.extract(r'CVE-(\\d{4})')\n"
     ]
    }
   ],
   "source": [
    "cleanData_NVD_full_new= cleanData_NVD_full\n",
    "cleanData_NVD_full_new['CVE_Year'] = cleanData_NVD_full_new['CVE'].str.extract(r'CVE-(\\d{4})')\n",
    "cleanData_NVD_new = cleanData_NVD_full_new[cleanData_NVD_full_new['CVE_Year'].astype(int) >= 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1.2.3 GHSA CVES Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "GHSA_cves = pd.read_json('./cve_data/GHSA_cves.json')\n",
    "\n",
    "GHSA_cves = GHSA_cves.rename(columns={  'cve_id' : 'CVE',\n",
    "                                          'description': 'Description', \n",
    "                                          'cvss_score': 'Score', \n",
    "                                          'cvss_vector': 'Vector',\n",
    "                                          'cwes':'CWE',\n",
    "                                         'package_name':'package'\n",
    "                                          \n",
    "                                          })\n",
    "GHSA_cves = GHSA_cves.drop(['severity'],axis=1)\n",
    "GHSA_cves = clean_descriptions(GHSA_cves, 'Description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleanData_GHSA = GHSA_cves.dropna(subset=['CVE', 'CWE','Description'])\n",
    "cleanData_GHSA = cleanData_GHSA.dropna(subset=['Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GHSA returns CWE as a list instead of a string, causing problems in our code.\n",
    "# List to string separated by a ','\n",
    "cleanData_GHSA['CWE'] = cleanData_GHSA['CWE'].apply(lambda x: ', '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows before dropna: 30870\n",
      "Number of rows after dropna: 18048\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of rows before dropna: {cleanData_GHSA.shape[0]}\")\n",
    "clean_GHSA = cleanData_GHSA.drop_duplicates()\n",
    "# Step 2: Remove rows where 'score' is equal to 0.0\n",
    "clean_GHSA = clean_GHSA[clean_GHSA['Score'] != 0.0]\n",
    "# Step 3: Remove rows where 'cwe' is ' '\n",
    "clean_GHSA = clean_GHSA[clean_GHSA['CWE'] != '']\n",
    "clean_GHSA = clean_GHSA.dropna(subset=['Vector','CWE'])\n",
    "print(f\"Number of rows after dropna: {clean_GHSA.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_GHSA.to_csv(\"./datasets/GitHub_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 2: Handling LLM scores**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 Budget Approximation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of CVES (103715, 11)\n",
      "Total cost for GPT-4o-mini: €4.283091\n",
      "Total cost for GPT-4o Global Deployment: €116.068432\n",
      "Total cost for gpt-4o-2024-08-06 Global Deployment: €67.164719\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from scripts.ai_bugdet_calculator import create_payload_and_calculate_tokens, \\\n",
    "    calculate_total_cost_per_model\n",
    "\n",
    "total_input = 0.0 \n",
    "total_output = 0.0 \n",
    "database= cleanData_NVD_full\n",
    "\n",
    "model_info = {\n",
    "    'GPT-4o-mini': {'input_price': 0.00014, 'output_price': 0.0006},\n",
    "    'GPT-4o Global Deployment': {'input_price': 0.0045, 'output_price': 0.0135},\n",
    "    'gpt-4o-2024-08-06 Global Deployment': {'input_price': 0.0023, 'output_price': 0.0090}\n",
    "}\n",
    "\n",
    "# Function to save results to JSON\n",
    "def save_results_to_json(cve_results, overall_total_cost, filename='payload_tokens.json'):\n",
    "    result = {\n",
    "        \"cve_results\": cve_results,\n",
    "        \"overall_total_cost\": overall_total_cost\n",
    "    }\n",
    "    with open(filename, 'w') as json_file:\n",
    "        json.dump(result, json_file, indent=4)\n",
    "\n",
    "# Function to save results to CSV\n",
    "def save_results_to_csv(cve_results, filename='payload_tokens.csv'):\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    df = pd.DataFrame.from_dict(cve_results, orient='index')\n",
    "    df.index.name = 'CVE ID'\n",
    "    df.reset_index(inplace=True)\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "print(f'Amount of CVES {database.shape}')\n",
    "\n",
    "for index,row in database.iterrows():\n",
    "    cve = row['CVE']\n",
    "    description = row['Description']\n",
    "    cwe = row['CWE']\n",
    "\n",
    "    cve_results, input_tokens, output_tokens = create_payload_and_calculate_tokens(cve, description, cwe)\n",
    "\n",
    "    # Update overall total cost\n",
    "    total_input += input_tokens\n",
    "    total_output += output_tokens\n",
    "\n",
    "\n",
    "calculate_total_cost_per_model(total_input,total_output,model_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 Resume from where it left off**\n",
    "*Continue from last CVE saved in CSV File*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remaining_data(csv_file, df_to_evaluate):\n",
    "    \"\"\"Return the remaining unprocessed data from the DataFrame.\"\"\"\n",
    "    results_df = load_existing_csv(csv_file)\n",
    "\n",
    "    if not results_df.empty:\n",
    "        # Get the last processed row index\n",
    "        last_index = results_df.index[-1]\n",
    "        print(f\"Resuming from index: {last_index + 1}\")\n",
    "        df_remaining = df_to_evaluate.iloc[last_index + 1:]\n",
    "    else:\n",
    "        print(\"Starting from the first row.\")\n",
    "        df_remaining = df_to_evaluate\n",
    "\n",
    "    return df_remaining, results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 CVSS3.1 CALCULATOR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvss import CVSS3\n",
    "\n",
    "def cvss_calculator(vector):\n",
    "    try:\n",
    "        cvss = CVSS3(vector)\n",
    "        return cvss.scores()[0]\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4 Prompt Request**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.chat import ask_bot\n",
    "from tqdm import tqdm\n",
    "\n",
    "def ai_scoring(model, df, csv_file):\n",
    "    # Get the remaining data to process based on the CSV file's progress\n",
    "    df_to_evaluate, results_df = get_remaining_data(csv_file, df)\n",
    "\n",
    "    # Set up the progress bar with tqdm\n",
    "    with tqdm(total=len(df_to_evaluate), desc=\"Processing CVEs\", unit=\"CVE\") as pbar:\n",
    "        for index, row in df_to_evaluate.iterrows():\n",
    "            cve = row['CVE']\n",
    "            description = row['Description']\n",
    "            cwe = row['CWE']\n",
    "\n",
    "            # Call the function from chat.py\n",
    "            score, vector, error = ask_bot(model, cve, description, cwe)\n",
    "            \n",
    "            # Handle critical errors (like 404 or connection issues) and save progress\n",
    "            if error == 404 or error == \"CONNECTION_ERROR\" or error == 401:\n",
    "                tqdm.write(f\"Critical error {error} for CVE: {cve}. Saving progress and exiting.\")\n",
    "                results_df.to_csv(csv_file, index=False)\n",
    "                return results_df # Stop processing further CVEs\n",
    "\n",
    "            # If no errors, append results\n",
    "            if score is not None and vector is not None:\n",
    "                \n",
    "                #Score based on given vector\n",
    "                calculated_score = cvss_calculator(vector)\n",
    "                \n",
    "                results_df = pd.concat([results_df, pd.DataFrame([{\n",
    "                    'CVE': cve,\n",
    "                    'Description': description,\n",
    "                    'CWE': cwe,\n",
    "                    'Score_LLM': score,\n",
    "                    'Calculated_Score_LLM' : calculated_score,\n",
    "                    'Vector_LLM': vector,\n",
    "\n",
    "                }])], ignore_index=True)\n",
    "\n",
    "                # Save progress after each CVE\n",
    "                results_df.to_csv(csv_file, index=False)\n",
    "            \n",
    "            # Print error message below the progress bar\n",
    "            if error:\n",
    "                tqdm.write(f\"Failed to retrieve CVSS score and vector for CVE: {cve} (Error: {error})\")\n",
    "            \n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5 Merge Score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_score(model,dataframe,suffix, csv_file, score=True):\n",
    "\n",
    "    # csv_file: model score file name. Format displays 'Llama_GHSA_merged_NVD' or 'Llama_GHSA_merged_GHSA' depending on comparison.\n",
    "    file_return = os.path.join('integrated_scores', f'{csv_file}_merged_{suffix}.csv')\n",
    "    model_file = os.path.join('model_scores', f'{model}_{suffix}.csv')\n",
    "\n",
    "    merged_df = load_existing_csv(file_return)\n",
    "\n",
    "    if score:\n",
    "        results_df = ai_scoring(model,dataframe, model_file)\n",
    "    else:\n",
    "        if not merged_df.empty:\n",
    "            return merged_df\n",
    "        results_df = load_existing_csv(model_file) #Load model score   \n",
    "    \n",
    "    results_df = results_df.merge(dataframe[['CVE', 'Score', 'Vector']], on='CVE', how='inner')\n",
    "    results_df = results_df.drop_duplicates(subset=['CVE'], keep='first')\n",
    "    #Save merge df in a new csv file to not alter saved LLM response\n",
    "    results_df.to_csv(file_return, index=False)\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 3: Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1 Define CVSS Category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to categorize CVSS scores based on ranges\n",
    "def get_cvss_category(score):\n",
    "    if score == 0.0:\n",
    "        return 'None'\n",
    "    elif 0.1 <= score <= 3.9:\n",
    "        return 'Low'\n",
    "    elif 4.0 <= score <= 6.9:\n",
    "        return 'Medium'\n",
    "    elif 7.0 <= score <= 8.9:\n",
    "        return 'High'\n",
    "    elif 9.0 <= score <= 10.0:\n",
    "        return 'Critical'\n",
    "    else:\n",
    "        return 'Invalid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2 Compare vector strings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compare two columns with CVSS strings in a DataFrame\n",
    "def compare_vector_columns(df, col1, col2):\n",
    "    # Function to compare two CVSS strings\n",
    "    def compare_vector_strings(vector1, vector2):\n",
    "        # Ensure that both vectors are strings (in case they are floats or NaN)\n",
    "        vector1 = str(vector1) if pd.notnull(vector1) else ''\n",
    "        vector2 = str(vector2) if pd.notnull(vector2) else ''\n",
    "        \n",
    "        # Split the CVSS strings into components by '/'\n",
    "        components1 = vector1.split('/')\n",
    "        components2 = vector2.split('/')\n",
    "\n",
    "        # Initialize an empty list to store the differences\n",
    "        differences = []\n",
    "\n",
    "        # Compare corresponding components from both CVSS strings\n",
    "        for comp1, comp2 in zip(components1, components2):\n",
    "            if comp1 != comp2:\n",
    "                differences.append(f\"{comp1} != {comp2}\")\n",
    "\n",
    "        # Join the differences into a single string and return it\n",
    "        return ','.join(differences) if differences else '0 diff'\n",
    "\n",
    "    # Apply the compare function row-wise and create a new column 'differences'\n",
    "    df['vector_diff'] = df.apply(lambda row: compare_vector_strings(row[col1], row[col2]), axis=1)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.3 Log Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_results(df, log, mean_deviation, mean_percentage_deviation, accuracy, log_file='log.txt'):\n",
    "    \n",
    "    # Format the log entry\n",
    "    log_entry = (\n",
    "        f\"\\nInnerJoin Rows: {df.shape[0]}\\n\"\n",
    "        f\"Mean Deviation: {mean_deviation}\\n\"\n",
    "        f\"Mean Percentage Deviation: {mean_percentage_deviation:.2f}%\\n\"\n",
    "        f\"Accuracy within same Severity Level: {accuracy:.2f}%\\n\\n\"\n",
    "    )\n",
    "\n",
    "    # Print the log entry to the console\n",
    "    print(log_entry)\n",
    "    log += log_entry\n",
    "    # Append the log entry to the log file\n",
    "    with open(log_file, 'a') as file:\n",
    "        file.write(log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.5 Evaluate Score accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_score_accuracy(log, df, original_score_column, llm_score_column, file_name):\n",
    "    # Convert the original and LLM score columns to float\n",
    "    df[original_score_column] = pd.to_numeric(df[original_score_column], errors='coerce')\n",
    "    df[llm_score_column] = pd.to_numeric(df[llm_score_column], errors='coerce')\n",
    "\n",
    "    # Calculate absolute deviation\n",
    "    df['Deviation'] = abs(df[original_score_column] - df[llm_score_column])\n",
    "\n",
    "    # Calculate percentage deviation\n",
    "    df['Percentage Deviation'] = (df['Deviation'] / df[original_score_column]) * 100\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # Calculate mean deviation and mean percentage deviation\n",
    "    mean_deviation = df['Deviation'].mean()\n",
    "    mean_percentage_deviation = df['Percentage Deviation'].mean()\n",
    "\n",
    "    # Apply the get_cvss_category function to both original and LLM scores\n",
    "    df['Original_Category'] = df[original_score_column].apply(get_cvss_category)\n",
    "    df['LLM_Category'] = df[llm_score_column].apply(get_cvss_category)\n",
    "\n",
    "    # Check if both original and LLM scores fall into the same category\n",
    "    df['Accurate'] = df['Original_Category'] == df['LLM_Category']\n",
    "\n",
    "    # Calculate accuracy as the percentage of scores that match within the same category\n",
    "    accuracy = (df['Accurate'].sum() / len(df)) * 100\n",
    "\n",
    "    # Log and Print results\n",
    "\n",
    "    log_results(df, log, mean_deviation, mean_percentage_deviation,accuracy)\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    df.to_csv(file_name, index=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.6 Call Evaluation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_evaluation(model, dataframe, suffix, csv_file, notes, score_and_evaluate=True):\n",
    "    current_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    log = f\"Log Time: {current_time}\\nModel: {model}\\nDataframe: {suffix}\\nDataFrame Rows: {dataframe.shape[0]}\\nNotes: {notes}\"\n",
    "\n",
    "    results = merge_and_score(model, dataframe, suffix, csv_file,score_and_evaluate)\n",
    "    \n",
    "    results = compare_vector_columns(results,'Vector_LLM','Vector')\n",
    "    evaluation = evaluate_score_accuracy(log, results, f'Score', 'Calculated_Score_LLM', f'./evaluation/Eval_{suffix}_{model}.csv')\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 4: Experimentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In the case you want to perform evaluation here in jupyternotebook\n",
    "#nvd_against_meta = get_evaluation(\"meta-llama-3.1-8b-instruct\",cleanData_NVD1, \"NVD_llama\", \"results\", \"NVD against llama\",False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = \"llama-3.1-8b-instruct\"\n",
    "# dataframe= clean_GHSA\n",
    "# suffix= \"GHSA\"\n",
    "# model_file = os.path.join('model_scores', f'{model}_{suffix}.csv')\n",
    "\n",
    "# ghsa_evaluation = ai_scoring(model,dataframe, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from index: 41881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CVEs:   0%|          | 0/51911 [00:01<?, ?CVE/s]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m suffix\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNVD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m model_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m nvd_against_meta \u001b[38;5;241m=\u001b[39m \u001b[43mai_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 41\u001b[0m, in \u001b[0;36mai_scoring\u001b[0;34m(model, df, csv_file)\u001b[0m\n\u001b[1;32m     30\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVE\u001b[39m\u001b[38;5;124m'\u001b[39m: cve,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m: description,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m     }])], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Save progress after each CVE\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mresults_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Print error message below the progress bar\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    310\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 313\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/_libs/writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "model = \"llama-3.1-8b-instruct\"\n",
    "dataframe= cleanData_NVD1\n",
    "suffix= \"NVD\"\n",
    "model_file = os.path.join('model_scores', f'{model}_{suffix}.csv')\n",
    "\n",
    "nvd_against_meta = ai_scoring(model,dataframe, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming from index: 20349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CVEs:   0%|          | 4/83366 [00:15<89:23:42,  3.86s/CVE]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m suffix\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNVD\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m model_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_scores\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m nvd_against_meta \u001b[38;5;241m=\u001b[39m \u001b[43mai_scoring\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[24], line 41\u001b[0m, in \u001b[0;36mai_scoring\u001b[0;34m(model, df, csv_file)\u001b[0m\n\u001b[1;32m     30\u001b[0m     results_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([results_df, pd\u001b[38;5;241m.\u001b[39mDataFrame([{\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCVE\u001b[39m\u001b[38;5;124m'\u001b[39m: cve,\n\u001b[1;32m     32\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription\u001b[39m\u001b[38;5;124m'\u001b[39m: description,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m     }])], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Save progress after each CVE\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[43mresults_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Print error message below the progress bar\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error:\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3775\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3777\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3779\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3789\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m start_i \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    310\u001b[0m data \u001b[38;5;241m=\u001b[39m [res\u001b[38;5;241m.\u001b[39miget_values(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(res\u001b[38;5;241m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_index[slicer]\u001b[38;5;241m.\u001b[39m_format_native_types(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_number_format)\n\u001b[0;32m--> 313\u001b[0m \u001b[43mlibwriters\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_csv_rows\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m    \u001b[49m\u001b[43mix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/ai_scoring/myvenv/lib/python3.8/site-packages/pandas/_libs/writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = \"gpt-4o-mini\"\n",
    "dataframe= cleanData_NVD_full\n",
    "suffix= \"NVD\"\n",
    "model_file = os.path.join('model_scores', f'{model}_{suffix}.csv')\n",
    "\n",
    "nvd_against_meta = ai_scoring(model,dataframe, model_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Chapter 5: DISPLAY RESULTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RUN Streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 12:44:28.904 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-24 12:44:28.911 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-24 12:44:28.912 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-09-24 12:44:28.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "!streamlit run script/fronted.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
